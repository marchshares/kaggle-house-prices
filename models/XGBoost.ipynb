{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "src_path = \"../src/\"\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from helpers_module import helpers as hlp\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error,mean_squared_log_error\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "plt.style.use(style='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE=27\n",
    "\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "test_id_col = test_df['Id']\n",
    "n_train = train_df.shape[0]\n",
    "n_test = test_df.shape[0]\n",
    "\n",
    "print(f\"Train rows: {n_train}, Test rows: {n_test}\")\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop train rows without target value\n",
    "train_df.dropna(subset = ['SalePrice'], inplace=True)\n",
    "\n",
    "# keep target column from train and keep it in variable\n",
    "target = train_df['SalePrice']\n",
    "train_df.drop(columns=['SalePrice'], inplace=True)\n",
    "\n",
    "# Concat train and test to common prepearing \n",
    "union_df = pd.concat([train_df, test_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepearing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hard drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hard list of columns to drop\n",
    "columns_to_drop_hard = ['Id']\n",
    "union_df = union_df.drop(columns_to_drop_hard, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_missing_values(df):\n",
    "    data = df.isna().sum().sort_values(ascending=False) / df.shape[0] * 100\n",
    "    data = data.head(10)\n",
    "\n",
    "    plt.figure(figsize=(16,12))\n",
    "    ax = sns.barplot(y=data.index, x=data.values)\n",
    "    ax.set_title(\"Missing values in %\")\n",
    "    \n",
    "print_missing_values(union_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check unique values in categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = hlp.get_unique_values_by_columns(union_df) \n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill categorical missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill 'None' in columns where NA mean None (e.g. no basement or garage)\n",
    "for col in [\n",
    "        'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "        'FireplaceQu', \n",
    "        'GarageFinish', 'GarageType', 'GarageQual', 'GarageCond',\n",
    "        'Alley', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "        'MasVnrType'\n",
    "    ] :\n",
    "\n",
    "    union_df[col].fillna('None', inplace=True)\n",
    "\n",
    "    \n",
    "# fill most frequent\n",
    "for col in [\n",
    "        'MSZoning', 'Functional', 'SaleType', 'Exterior2nd', 'Exterior1st', 'KitchenQual', 'Electrical'\n",
    "    ]:\n",
    "    \n",
    "    union_df[col].fillna(union_df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax = union_df['Utilities'].value_counts().plot(kind='bar')\n",
    "ax.set_title('Utilities')\n",
    "\n",
    "# non-informative - just drop\n",
    "union_df.drop(columns=['Utilities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fill numerical missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fill median of Neighborhood (locations) in LotFrontage\n",
    "union_df[\"LotFrontage\"] = union_df\\\n",
    "                            .groupby(\"Neighborhood\")[\"LotFrontage\"]\\\n",
    "                            .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "for col in [\n",
    "        'GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "        'MasVnrArea',\n",
    "        'BsmtFullBath','BsmtHalfBath','TotalBsmtSF','BsmtUnfSF','BsmtFinSF2', 'BsmtFinSF1'\n",
    "    ]:\n",
    "    \n",
    "    union_df[col].fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "numeric_cols = hlp.get_numeric_cols(union_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Check missing values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Count of missing values: \", union_df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat=2\n",
    "\n",
    "# 1. Just drop all categorial columns\n",
    "if cat == 1:\n",
    "    union_df = hlp.drop_str_cols(union_df)\n",
    "\n",
    "# ------ OR ------\n",
    "\n",
    "# 2. Encode by simple labels\n",
    "if cat == 2:\n",
    "    union_df = hlp.encode_with_labels(union_df)\n",
    "\n",
    "# ------ OR ------\n",
    "\n",
    "# 3. Encode by one hot\n",
    "if cat == 3:\n",
    "    union_df = hlp.encode_with_one_hot(union_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Numerical columns processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# min_max_scaler = MinMaxScaler()\n",
    "# union_df = min_max_scaler.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = union_df[:n_train]\n",
    "test_df = union_df[n_train:]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Prepearing for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices are right skewed - will use log to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Skew is:\", target.skew())\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "sns.histplot(target, kde=True, ax=axes[0])\n",
    "sns.histplot(np.log1p(target), kde=True, ax=axes[1], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = train_df\n",
    "y = np.log1p(target)\n",
    "\n",
    "X_test = test_df\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best hyperparameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "need_find_best_params=False\n",
    "\n",
    "if need_find_best_params:\n",
    "    xgb_params = {\n",
    "        'colsample_bytree': 0.3, \n",
    "        'learning_rate': 0.05, \n",
    "        'max_depth': 3, \n",
    "        'min_child_weight': 1, \n",
    "        'reg_alpha': 0, \n",
    "        'reg_lambda': 2, \n",
    "        'subsample': 0.5\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [500,600,700,800,900,1000,1200,1500,1700,2000,2500,3000,4000,5000]\n",
    "    }\n",
    "\n",
    "\n",
    "    reserch_model = XGBRegressor(**xgb_params)\n",
    "\n",
    "    xgb_rscv = GridSearchCV(reserch_model, param_grid = param_grid, \n",
    "                                  scoring='neg_mean_squared_error',\n",
    "                                  n_jobs=4,\n",
    "                                  cv=5,\n",
    "                                  verbose = True)\n",
    "\n",
    "#     model_xgboost = xgb_rscv.fit(X_train, y_train,early_stopping_rounds=200,\n",
    "#               eval_set=[(X_valid, y_valid)], eval_metric='rmsle', verbose=False)\n",
    "\n",
    "    model_xgboost = xgb_rscv.fit(X, y, eval_metric='rmse', verbose=False)\n",
    "\n",
    "    best_params = model_xgboost.best_params_\n",
    "    print(f\"Best score: {model_xgboost.best_score_:.5f} \\nBest params: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal  n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# xgb_params = best_params\n",
    "\n",
    "# xgb_params = {    \n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"max_depth\": 3,    \n",
    "#     'reg_lambda': 1.5,\n",
    "#     'n_estimators': 500\n",
    "# }\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 0.3, \n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': 3, \n",
    "    'min_child_weight': 1, \n",
    "    'n_estimators': 700, \n",
    "    'reg_alpha': 0, \n",
    "    'reg_lambda': 2, \n",
    "    'subsample': 0.5\n",
    "}\n",
    "\n",
    "reserch_model = XGBRegressor(**xgb_params)\n",
    "\n",
    "reserch_model.fit(X_train, y_train, early_stopping_rounds=200, \n",
    "          eval_set=[(X_valid, y_valid)], eval_metric='rmse', verbose=False)\n",
    "\n",
    "y_train_pred = reserch_model.predict(X_train)\n",
    "y_valid_pred = reserch_model.predict(X_valid)\n",
    "\n",
    "print(\"RMSE train: {:.5f}\".format(sqrt(mean_squared_error(y_train, y_train_pred))))\n",
    "print(\"RMSE: {:.5f}\".format(sqrt(mean_squared_error(y_valid, y_valid_pred))))\n",
    "print(\"R2: {:.5f}\".format(r2_score(y_valid, y_valid_pred)))\n",
    "print(\"Best: {:.5f}, iter={:d}\".format(reserch_model.best_score, reserch_model.best_iteration))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross score check by rmse and r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_params['n_estimators'] = reserch_model.best_iteration\n",
    "\n",
    "# check by r2 score by cross validation\n",
    "model_for_cross_val = XGBRegressor(**xgb_params)\n",
    " \n",
    "scores = cross_validate(model_for_cross_val, X, y,\n",
    "                        n_jobs=4, cv=5,\n",
    "                        scoring=('r2', 'neg_mean_squared_error'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "print(\"RMSE train mean: {:10.5f}\".format(scores['train_neg_mean_squared_error'].mean()))\n",
    "print(\"R2 train mean:   {:10.5f}\".format(scores['train_r2'].mean()))\n",
    "print(\"----\")\n",
    "print(\"RMSE test mean:  {:10.5f}\".format(scores['test_neg_mean_squared_error'].mean()))\n",
    "print(\"R2 test mean:    {:10.5f}\".format(scores['test_r2'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_final = XGBRegressor(**xgb_params)\n",
    "model_final.fit(X, y)\n",
    "\n",
    "y_train_pred = model_final.predict(X)\n",
    "\n",
    "print(\"RMSE train: {:.5f}\".format(sqrt(mean_squared_error(y, y_train_pred))))\n",
    "print(\"RMSLE train: {:.5f}\".format(sqrt(mean_squared_log_error(y, y_train_pred))))\n",
    "print(\"R2 train: {:.5f}\".format(r2_score(y, y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def params_to_str(params):\n",
    "    res = \"\"\n",
    "    for k,v in params.items():\n",
    "        for s in k.split('_'):\n",
    "            res += s[:2]\n",
    "        res += str(v)\n",
    "        res += \"_\"\n",
    "        \n",
    "    return res[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.expm1(model_final.predict(X_test))\n",
    "\n",
    "output = pd.DataFrame({'Id': test_id_col, 'SalePrice': y_test_pred})\n",
    "output.to_csv(f'../data/rmse_{rmse:.5f}_xgb{reserch_model.best_iteration}_r_Id_enc-cat{cat}_logy_{params_to_str(xgb_params)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (py-notes2)",
   "language": "python",
   "name": "pycharm-ec69c579"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}